\documentclass[english]{tktltiki}
\usepackage[pdftex]{graphicx}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{url}
\usepackage{xcolor}
\usepackage{amsmath}
\begin{document}


\onehalfspacing
\title{Reinforcement Learning in Games: A Mini Survey}
\author{Ege Can Özer}
\date{\today}

\maketitle
\numberofpagesinformation{\numberofpages\ pages + \numberofappendixpages\ appendices}

\classification{\protect{\ \\
	A.1 [Introductory and Survey],\\
	I.7.m [Document and text processing]}}

\keywords{Reinforcement Learning}

\begin{abstract}
    Self-learning programs have been studied and applied in many different fields; but recently, it gains more popularity and familiarity due to its breakthrough success in the game domain. Unlike the examples are taken from the real world, having the pre-defined set of rules and the less complicated environment in this domain provides greater flexibility to develop reinforcement learning algorithms. In this paper, we will study the applications of reinforcement learning algorithms in the game context by closely focusing on five different articles. Based on the findings, we hope to propose possible improvements for future studies.
\end{abstract}

\mytableofcontents

\section{Introduction}
During the last decade, reinforcement learning paradigm, despite being actually not a new concept, has gained decent amount of popularity. Starting from middle 80's and ever since then, it has been applied in many fields to address complex problems such as in robotics, control systems, finance, and agent-based systems due to its generic formulation. In its essence, reinforcement learning concept looks for optimal input actions that maximizes the output states by making use of the feedbacks from environment \cite{tesauro1995temporal}. In spite of the fact that RL being a mature and widely-used concept, the primary reason to get such attention recently is due to breakthrough success in the game context \cite{mnih2013playing, silver2016mastering}.

Studying reinforcement learning algorithms in the game context contributes several definitive advantages \cite{tesauro1995temporal}. In general, modeling of the problem, implementation, and analysis of the results in real life examples are harder than the artificial ones such as games. Moreover, having simplified and controlled environment, as well as specifically defined rule sets not only allow an opportunity to explore the new variety of RL algorithms, but also enable to have concrete evaluation measurements. Further, research results are reproducible, easy to simulate and provide test-bed for future studies. Therefore, for the given reasons, studying reinforcement learning in games can help the field to progress further and more effectively.

Advancement in a scientific field affect one to another and grants to improve even more towards advancement; the notion enables opportunity to observe the advancements, yet to come, obtained by the RL in games. The usual case is where the previous developments leads to a new one, such an example appears in the article by Gerald Tesauro \cite{tesauro1995temporal} that combines neural network and temporal difference concepts into new one. Another case is that advancements in the related fields drive a new one. For example, Mnih et al. \cite{mnih2013playing} proposes a deep learning model that learns control policies directly from sensory(image, video) input, which made it possible by computer vision and speech recognition research fields. As a matter of fact, this mini survey, in some sense, will explore the final case that how RL in game context can affect the other fields.

*Refactor last paragraph later*

In this paper, we review five different reinforcement learning systems in game context. The rest of the paper is organized as follows. In section 2, we examine each articles in detail, how do they tackle the problem, and how RL is used and what are their flaws. In section 3, we propose possible improvements that can be taken to help to improve the field. Last section, summarizes and concludes the paper.

\section{Application of Reinforcement Learning to Games}
** Introduce this section, what is going to happen, how we are going to explore the articles, in what order, in which structure, lastly we will compare**
\subsection{Basic outline to follow}
\begin{itemize}
    \item What is the problem, introduce environment
    \item Proposed solution to the problem
    \item Results
\end{itemize}
\subsection{Mario: Q-Learning}
Everything is defined in this model. Low-level design of the environment, everything is known.
\subsection{Civilization 4: High Level RL Approach}
RL used as a high level strategy planning, they let the game's AI handle the low-level operations.
\subsection{TD Gammon: First Success}
First important step towards AI in games using RL.
\subsection{Atari Games: Context Free Approach DQN}
Raw sensory input data to train bunch of different games without knowing its internal elements explicitly. I need to read this more deeply.
\subsection{Mastering the Game of Go}
Read this again!

\section{Future Researches}
\begin{itemize}
    \item Evaluation frameworks, point out many systems, human comparison
    \item Sandbox learning, can this be used to train DQN approach and applied on other games? This way one may not to deal with the context at all? RL in games, may help other 
    \item Need for a theoratical framework to describe the RL papers that encapsulating some context. Similar frameworks exist in the view of computational creativity world. This would provide more structural way for reseaches to present their case studies, but also to describe the candidate systems regardless of what they use. A theoretical framework, such as that presented here, may be useful in teasing out philosophical issues, but it may also be useful in giving generalised descriptions of behaviours which might be observed in creative agents. Self-critics about writing this paper, more structured way to review RL systems in terms of some theoratical framework.
\end{itemize}

\section{Conclusion}
Recap everything

\nocite{*}
\bibliographystyle{tktl}
\bibliography{lahteet}

\lastpage

\appendices

\pagestyle{empty}



\end{document}


